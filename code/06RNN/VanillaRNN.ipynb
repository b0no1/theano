{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 960\n"
     ]
    }
   ],
   "source": [
    "### http://deeplearning.net/tutorial/rnnslu.html ###\n",
    "## https://github.com/dennybritz/rnn-tutorial-rnnlm/blob/master/rnn_theano.py ##\n",
    "#https://github.com/dennybritz/rnn-tutorial-rnnlm/blob/master/train-theano.py#\n",
    "#http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/#\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------#\n",
    "## Start building the model ##\n",
    "class RecurrentNet(object):\n",
    "    def __init__(self,num_h=100,word_dim=8000,bptt_truncate=4):\n",
    "        self.num_h = num_h\n",
    "        self.word_dim = word_dim\n",
    "        self.bptt_truncate = bptt_truncate\n",
    "        # init network param Wih,Who,Whh\n",
    "        Wih_val = np.random.uniform(-np.sqrt(1./word_dim), np.sqrt(1./word_dim),(num_h,word_dim))\n",
    "        Whh_val = np.random.uniform(-np.sqrt(1./num_h), np.sqrt(1./num_h),(num_h,num_h))\n",
    "        Who_val = np.random.uniform(-np.sqrt(1./num_h), np.sqrt(1./num_h),(word_dim,num_h))\n",
    "        # set value to shared variables\n",
    "        self.Wih = theano.shared(value=Wih_val.astype(theano.config.floatX),borrow=True,name='Wih')\n",
    "        self.Whh = theano.shared(value=Whh_val.astype(theano.config.floatX),borrow=True,name='Whh')\n",
    "        self.Who = theano.shared(value=Who_val.astype(theano.config.floatX),borrow=True,name='Who')\n",
    "        # setup biases\n",
    "        self.bh = theano.shared(np.zeros((num_h,1)).astype(theano.config.floatX),borrow=True, name='bh')\n",
    "        self.bo = theano.shared(np.zeros((word_dim,1)).astype(theano.config.floatX),borrow=True, name='bo')\n",
    "        # state of hidden layer/network\n",
    "        state_val = np.zeros(shape=(100,1),dtype=theano.config.floatX)\n",
    "        self.state = theano.shared(value=state_val,borrow=True,name='state')\n",
    "        # cost\n",
    "        self.params = self.Whh + self.Wih + self.Who + self.bh + self.bo\n",
    "        self.error = ((y - t) ** 2).sum()\n",
    "        \n",
    "    \n",
    "    # forward propagation\n",
    "    def fstep(self,i_t,h_tm1,Whh,Wih,Who,bh,bo):\n",
    "        # given input i, calculate current state \n",
    "        h_t = T.tanh(T.dot(Whh,h_tm1) + T.dot(Wih,i_t) + bh)\n",
    "        y_t = T.dot(Who,h_tm1) + bo\n",
    "        return h_t,y_t\n",
    "    \n",
    "    def cost(t,y):\n",
    "        return T.sum(T.nnet.categorical_crossentropy(t, y))\n",
    "    \n",
    "       # def error(t,y):\n",
    "    #    return ((y - t) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = T.matrix('x')\n",
    "t = T.vector('t')\n",
    "#y = T.vector('y')\n",
    "lr = T.scalar('lr')\n",
    "\n",
    "\n",
    "rn = RecurrentNet()\n",
    "\n",
    "h0 = T.matrix()\n",
    "\n",
    "# theano.scan for running the recurrence loop\n",
    "[h, y], _ = theano.scan(rn.fstep,\n",
    "                        sequences=x,\n",
    "                        outputs_info=[h0, None],\n",
    "                        non_sequences=[rn.Whh, rn.Wih, rn.Who, rn.bh, rn.bo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "DisconnectedInputError",
     "evalue": "grad method was asked to compute the gradient with respect to a variable that is not part of the computational graph of the cost, or is used only by a non-differentiable operator: Elemwise{add,no_inplace}.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDisconnectedInputError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-afee1e7c86fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(cost, wrt, consider_constant, disconnected_inputs, add_names, known_grads, return_disconnected)\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvar_to_app_to_idx\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m                 \u001b[1;32mand\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrad_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m             \u001b[0mhandle_disconnected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m             \u001b[0mgrad_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisconnected_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gradient.pyc\u001b[0m in \u001b[0;36mhandle_disconnected\u001b[1;34m(var)\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mdisconnected_inputs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mDisconnectedInputError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m                 raise ValueError(\"Invalid value for keyword \"\n",
      "\u001b[1;31mDisconnectedInputError\u001b[0m: grad method was asked to compute the gradient with respect to a variable that is not part of the computational graph of the cost, or is used only by a non-differentiable operator: Elemwise{add,no_inplace}.0"
     ]
    }
   ],
   "source": [
    "#gradients\n",
    "error = ((y - t) ** 2).sum()\n",
    "gparams = T.grad(error, [rn.Whh, rn.Wih, rn.Who, rn.bh, rn.bo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:9: UserWarning: The parameter 'updates' of theano.function() expects an OrderedDict, got <type 'dict'>. Using a standard dictionary here results in non-deterministic behavior. You should use an OrderedDict if you are using Python 2.7 (theano.compat.python2x.OrderedDict for older python), or use a list of (shared, update) pairs. Do not just convert your dictionary to this type before the call as the conversion will still be non-deterministic.\n"
     ]
    }
   ],
   "source": [
    "# train function\n",
    "# SGD.\n",
    "fn = theano.function([h0, x, t, lr],\n",
    "                     error,\n",
    "                     updates={rn.Whh: rn.Whh - lr *gWhh,\n",
    "                             rn.Wih: rn.Wih - lr * gWih,\n",
    "                             rn.Who: rn.Who - lr * gWho,\n",
    "                             rn.bh: rn.bh - lr * gbh,\n",
    "                             rn.bo: rn.bo - lr * gbo}\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<theano.compile.function_module.Function at 0x7f8646b0c450>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
