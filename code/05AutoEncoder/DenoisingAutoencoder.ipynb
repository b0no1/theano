{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Autoencoder : http://deeplearning.net/tutorial/dA.html ##\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from logistic import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenoisingAutoencoder(object):\n",
    "    def __init__(self,input,rng,num_v,num_h):\n",
    "        self.num_h = num_h\n",
    "        self.num_v = num_v\n",
    "        # init weight\n",
    "        wval = np.asarray(rng.uniform(low=-4 * np.sqrt(6. / (num_h + num_v)),\n",
    "                                      high=4 * np.sqrt(6. / (num_h + num_v)),\n",
    "                                      size=(num_v,num_h)),dtype=theano.config.floatX)\n",
    "        self.w = theano.shared(value=wval,name='w',borrow = True)\n",
    "        # init visible layer bias\n",
    "        self.bv = theano.shared(value = np.zeros(num_v,dtype=theano.config.floatX),name='bv',borrow=True)\n",
    "        # init hidden layer bias\n",
    "        self.bh = theano.shared(value = np.zeros(num_h,dtype=theano.config.floatX),name='bh',borrow=True)\n",
    "        # setup weight hidden-output layer connections\n",
    "        #  -> tied weights\n",
    "        self.w_ = self.w.T\n",
    "        self.x = input\n",
    "        self.params = [self.w,self.bv,self.bh]\n",
    "        \n",
    "    def encode(self,x_):\n",
    "        return T.nnet.sigmoid(T.dot(x_,self.w) + self.bh) ### Notice the use of bh here ###\n",
    "    \n",
    "    def decode(self,code):\n",
    "        return T.nnet.sigmoid(T.dot(code,self.w_) + self.bv) ### Notice the use of bv here ###\n",
    "    \n",
    "    def loss(self,y,z):\n",
    "        return - T.sum(self.x * T.log(z) + (1 - self.x) * T.log(1 - z), axis=1)\n",
    "\n",
    "    def cost(self,y,z):\n",
    "        return T.mean(self.loss(y,z))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "# get corrupted input\n",
    "rng = np.random.RandomState(123)\n",
    "theano_rng = RandomStreams(rng.randint(2 ** 30))\n",
    "\n",
    "def corrupt_x(x,theano_rng,corruption_level):\n",
    "    return theano_rng.binomial(size=x.shape, n=1,\n",
    "                                        p=1 - corruption_level,\n",
    "                                        dtype=theano.config.floatX) * x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = T.matrix('x')\n",
    "\n",
    "da = DenoisingAutoencoder(rng=rng,input=x,num_v=28*28,num_h=500)\n",
    "\n",
    "# corrupt x\n",
    "x_ = corrupt_x(da.x,theano_rng,0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# symbolic expressions for y and z\n",
    "y = da.encode(x_)\n",
    "z = da.decode(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup cost, gradients and updates\n",
    "cost = da.cost(y,z)\n",
    "\n",
    "# gradients\n",
    "gparams = T.grad(cost,da.params)\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# updates\n",
    "updates = [ (param, param - (learning_rate*gparam) )\n",
    "              for param,gparam in zip(da.params,gparams)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "datasets = load_data('mnist.pkl.gz')\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "train_set_x, train_set_y = datasets[0]\n",
    "valid_set_x, valid_set_y = datasets[1]\n",
    "test_set_x, test_set_y = datasets[2]\n",
    "\n",
    "# compute number of minibatches for training, validation and testing\n",
    "n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "n_valid_batches = valid_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "n_test_batches = test_set_x.get_value(borrow=True).shape[0] / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = T.lscalar('index')\n",
    "\n",
    "\n",
    "# compile train function\n",
    "train = theano.function(inputs=[index],\n",
    "                        outputs=cost,\n",
    "                        updates=updates,\n",
    "                       givens={ x : train_set_x[index*batch_size : (index+1)*batch_size]}\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# actual training\n",
    "for j in xrange(100):\n",
    "    cost_iter = 0\n",
    "    for i in xrange(n_train_batches):\n",
    "        cost_iter +=  train(i)\n",
    "    print 'cost per iteration : ',cost_iter/n_train_batches\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
