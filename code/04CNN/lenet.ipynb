{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## >> http://deeplearning.net/tutorial/lenet.html << ##\n",
    "import numpy as np\n",
    "\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import theano.tensor.nnet as conv\n",
    "\n",
    "from theano.tensor.signal import downsample\n",
    "\n",
    "from logistic import load_data,LogisticRegression\n",
    "from mlp import HiddenLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConvPoolLayer(object):\n",
    "    def __init__(self,rng,input,filter_shape,image_shape, pool_size=(2,2) ):\n",
    "        # check if filter shape matches the input shape\n",
    "        assert image_shape[1] == filter_shape[1]\n",
    "        # >>>> self.input = input\n",
    "        # number of inputs to each hidden unit: fan_in\n",
    "        fan_in = np.prod(filter_shape[1:]) # 1x5x5 : receptive field 5x5 of grayscale image\n",
    "        # fan_out to lower layer (left)\n",
    "        #  for gradient propagation\n",
    "        #   20 * 5x5 connections\n",
    "        fan_out = filter_shape[0] * np.prod(filter_shape[2:]) # 20 * (5x5) : nkern[0] * (5x5)\n",
    "        # random initialization of weights\n",
    "        wbound = np.sqrt(6. / (fan_in + fan_out))\n",
    "        wval = np.asarray(rng.uniform(low = -wbound, high = wbound, size=filter_shape),\n",
    "                          dtype = theano.config.floatX)\n",
    "        self.w = theano.shared(wval,name='w',borrow = True)\n",
    "        # bias term \n",
    "        self.b = theano.shared(np.zeros((filter_shape[0],),dtype=theano.config.floatX),name='b', borrow=True)\n",
    "        # convol operation\n",
    "        conv_out = conv.conv2d(input,self.w,filter_shape=filter_shape,image_shape=image_shape, border_mode='full')\n",
    "        # pooling : downsampling\n",
    "        pooled = downsample.max_pool_2d(input=conv_out,ds=pool_size,ignore_border=True)\n",
    "        # apply non-linearity and bias to pooled output\n",
    "        #  dimshuffle : convert shape of bias from (filter_shape[0],) to (1, n_filters, 1, 1)\n",
    "        self.output = T.tanh(pooled + self.b.dimshuffle('x',0,'x','x'))\n",
    "        # store params\n",
    "        self.params = [self.w,self.b]\n",
    "        self.input = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data\n",
    "datasets = load_data('TamilCh.pkl.gz')\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "train_set_x, train_set_y = datasets[0]\n",
    "valid_set_x, valid_set_y = datasets[1]\n",
    "test_set_x, test_set_y = datasets[2]\n",
    "\n",
    "# compute number of minibatches for training, validation and testing\n",
    "n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "n_valid_batches = valid_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "n_test_batches = test_set_x.get_value(borrow=True).shape[0] / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = T.matrix('x')\n",
    "y = T.ivector('y')\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "# convert input x to form (batch_size,1,28,28)\n",
    "layer0_input = x.reshape((batch_size,1,30,30))\n",
    "\n",
    "# setup random stream\n",
    "rng = np.random.RandomState(123455)\n",
    "\n",
    "# build layer0\n",
    "layer0 = ConvPoolLayer(rng=rng,input=layer0_input,\n",
    "                      image_shape=(batch_size,1,30,30),\n",
    "                      filter_shape=(20,1,5,5))\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Layer 1 setup ##\n",
    "layer1 = ConvPoolLayer(rng=rng,input=layer0.output,\n",
    "                      image_shape=(batch_size,20,14,14),\n",
    "                      filter_shape=(50,20,5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Layer 2 : Hidden Layer setup ##\n",
    "# layer1 output shape : batch_sizex50x4x4\n",
    "# layer2_h input shape req : batch_size x (50*4*4)\n",
    "layer2_h_input = layer1.output.flatten(2)\n",
    "# n_in = 50x4x4 pixels; n_out = 500 hidden nodes\n",
    "layer2_h = HiddenLayer(rng=rng,input=layer2_h_input,n_in=50*5*5,n_out=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Layer 3 : Output layer : LogisticRegression\n",
    "layer3_o = LogisticRegression(input=layer2_h.output,n_in=500,n_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost \n",
    "cost = layer3_o.neg_log_likelihood(y)\n",
    "# >> setup gradient expression <<\n",
    "### Need :parameters\n",
    "params = layer3_o.params + layer2_h.params + layer1.params + layer0.params\n",
    "gparams = T.grad(cost,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Updates ##\n",
    "updates = [(param, param - gparam*learning_rate) \n",
    "              for param,gparam in zip(params,gparams)]\n",
    "\n",
    "\n",
    "index = T.lscalar('index')\n",
    "# compile train\n",
    "train = theano.function(inputs=[index],\n",
    "                        outputs=cost,\n",
    "                        updates=updates,\n",
    "                        givens = { x : train_set_x[index*batch_size : (index +1)*batch_size],\n",
    "                                   y : train_set_y[index*batch_size : (index +1)*batch_size]}\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch in args to gemm (500,5000)x(1250,500)->(500,500)\nApply node that caused the error: GpuDot22(GpuElemwise{tanh,no_inplace}.0, w)\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(500, 5000), (1250, 500)]\nInputs strides: [(5000, 1), (500, 1)]\nInputs values: ['not shown', 'not shown']\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ff20b304cb6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_train_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mminibatch_avg_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'iteration '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' : cost : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatch_avg_cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    604\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthunks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m                         storage_map=self.fn.storage_map)\n\u001b[0m\u001b[0;32m    607\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m                     \u001b[1;31m# For the c linker We don't have access from\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: dimension mismatch in args to gemm (500,5000)x(1250,500)->(500,500)\nApply node that caused the error: GpuDot22(GpuElemwise{tanh,no_inplace}.0, w)\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(500, 5000), (1250, 500)]\nInputs strides: [(5000, 1), (500, 1)]\nInputs values: ['not shown', 'not shown']\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "# Actual training #\n",
    "# Actual training begins here\n",
    "minibatch_avg_cost = 0\n",
    "for j in xrange(300):\n",
    "    for i in xrange(n_train_batches):\n",
    "        minibatch_avg_cost = train(i)        \n",
    "    print 'iteration ',j,' : cost : ', minibatch_avg_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testing\n",
    "test = theano.function(inputs = [index],\n",
    "                      outputs = layer3_o.errors(y),\n",
    "                      givens = { x : test_set_x[index*batch_size : (index +1)*batch_size],\n",
    "                                 y : test_set_y[index*batch_size : (index +1)*batch_size]\n",
    "                               }\n",
    "                      )\n",
    "error_sum = 0.0\n",
    "for i in xrange(n_test_batches):\n",
    "    error_sum += test(i)\n",
    "print 'avg_error : ',error_sum/n_test_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize feature maps in convolnet\n",
    "visual = theano.function(inputs=[index],\n",
    "                        outputs = [layer3_o.errors(y),layer0.output],\n",
    "                        givens = { x : valid_set_x[index*batch_size : (index+1)*batch_size],\n",
    "                                   y : valid_set_y[index*batch_size : (index+1)*batch_size]\n",
    "                                 }\n",
    "                        )\n",
    "\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "er,imcluster0 = visual(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pylab.gray()\n",
    "\n",
    "pylab.imshow(imcluster0[3,0,:,:])\n",
    "#pylab.savefig('im01.png')\n",
    "\n",
    "for i in xrange(20):\n",
    "    pylab.imshow(imcluster0[3,i,:,:])\n",
    "    #pylab.show()\n",
    "    pylab.savefig('im%d.png'%(i))\n",
    "#pylab.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
