{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## >> http://deeplearning.net/tutorial/lenet.html << ##\n",
    "import numpy as np\n",
    "\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import theano.tensor.nnet as conv\n",
    "\n",
    "from theano.tensor.signal import downsample\n",
    "\n",
    "from logistic import load_data,LogisticRegression\n",
    "from mlp import HiddenLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConvPoolLayer(object):\n",
    "    def __init__(self,rng,input,filter_shape,image_shape, pool_size=(2,2) ):\n",
    "        # check if filter shape matches the input shape\n",
    "        assert image_shape[1] == filter_shape[1]\n",
    "        # >>>> self.input = input\n",
    "        # number of inputs to each hidden unit: fan_in\n",
    "        fan_in = np.prod(filter_shape[1:]) # 1x5x5 : receptive field 5x5 of grayscale image\n",
    "        # fan_out to lower layer (left)\n",
    "        #  for gradient propagation\n",
    "        #   20 * 5x5 connections\n",
    "        fan_out = filter_shape[0] * np.prod(filter_shape[2:]) # 20 * (5x5) : nkern[0] * (5x5)\n",
    "        # random initialization of weights\n",
    "        wbound = np.sqrt(6. / (fan_in + fan_out))\n",
    "        wval = np.asarray(rng.uniform(low = -wbound, high = wbound, size=filter_shape),\n",
    "                          dtype = theano.config.floatX)\n",
    "        self.w = theano.shared(wval,name='w',borrow = True)\n",
    "        # bias term \n",
    "        self.b = theano.shared(np.zeros((filter_shape[0],),dtype=theano.config.floatX),name='b', borrow=True)\n",
    "        # convol operation\n",
    "        conv_out = conv.conv2d(input,self.w,filter_shape=filter_shape,image_shape=image_shape)\n",
    "        # pooling : downsampling\n",
    "        pooled = downsample.max_pool_2d(input=conv_out,ds=pool_size,ignore_border=True)\n",
    "        # apply non-linearity and bias to pooled output\n",
    "        #  dimshuffle : convert shape of bias from (filter_shape[0],) to (1, n_filters, 1, 1)\n",
    "        self.output = T.tanh(pooled + self.b.dimshuffle('x',0,'x','x'))\n",
    "        # store params\n",
    "        self.params = [self.w,self.b]\n",
    "        self.input = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "datasets = load_data('mnist.pkl.gz')\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "train_set_x, train_set_y = datasets[0]\n",
    "valid_set_x, valid_set_y = datasets[1]\n",
    "test_set_x, test_set_y = datasets[2]\n",
    "\n",
    "# compute number of minibatches for training, validation and testing\n",
    "n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "n_valid_batches = valid_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "n_test_batches = test_set_x.get_value(borrow=True).shape[0] / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = T.matrix('x')\n",
    "y = T.ivector('y')\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "# convert input x to form (batch_size,1,28,28)\n",
    "layer0_input = x.reshape((batch_size,1,28,28))\n",
    "\n",
    "# setup random stream\n",
    "rng = np.random.RandomState(123455)\n",
    "\n",
    "# build layer0\n",
    "layer0 = ConvPoolLayer(rng=rng,input=layer0_input,\n",
    "                      image_shape=(batch_size,1,28,28),\n",
    "                      filter_shape=(20,1,5,5))\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Layer 1 setup ##\n",
    "layer1 = ConvPoolLayer(rng=rng,input=layer0.output,\n",
    "                      image_shape=(batch_size,20,12,12),\n",
    "                      filter_shape=(50,20,5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Layer 2 : Hidden Layer setup ##\n",
    "# layer1 output shape : batch_sizex50x4x4\n",
    "# layer2_h input shape req : batch_size x (50*4*4)\n",
    "layer2_h_input = layer1.output.flatten(2)\n",
    "# n_in = 50x4x4 pixels; n_out = 500 hidden nodes\n",
    "layer2_h = HiddenLayer(rng=rng,input=layer2_h_input,n_in=50*4*4,n_out=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Layer 3 : Output layer : LogisticRegression\n",
    "layer3_o = LogisticRegression(input=layer2_h.output,n_in=500,n_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost \n",
    "cost = layer3_o.neg_log_likelihood(y)\n",
    "# >> setup gradient expression <<\n",
    "### Need :parameters\n",
    "params = layer3_o.params + layer2_h.params + layer1.params + layer0.params\n",
    "gparams = T.grad(cost,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Updates ##\n",
    "updates = [(param, param - gparam*learning_rate) \n",
    "              for param,gparam in zip(params,gparams)]\n",
    "\n",
    "\n",
    "index = T.lscalar('index')\n",
    "# compile train\n",
    "train = theano.function(inputs=[index],\n",
    "                        outputs=cost,\n",
    "                        updates=updates,\n",
    "                        givens = { x : train_set_x[index*batch_size : (index +1)*batch_size],\n",
    "                                   y : train_set_y[index*batch_size : (index +1)*batch_size]}\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Actual training #\n",
    "# Actual training begins here\n",
    "minibatch_avg_cost = 0\n",
    "for j in xrange(300):\n",
    "    for i in xrange(n_train_batches):\n",
    "        minibatch_avg_cost = train(i)        \n",
    "    print 'iteration ',j,' : cost : ', minibatch_avg_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testing\n",
    "test = theano.function(inputs = [index],\n",
    "                      outputs = layer3_o.errors(y),\n",
    "                      givens = { x : test_set_x[index*batch_size : (index +1)*batch_size],\n",
    "                                 y : test_set_y[index*batch_size : (index +1)*batch_size]\n",
    "                               }\n",
    "                      )\n",
    "error_sum = 0.0\n",
    "for i in xrange(n_test_batches):\n",
    "    error_sum += test(i)\n",
    "print 'avg_error : ',error_sum/n_test_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize feature maps in convolnet\n",
    "visual = theano.function(inputs=[index],\n",
    "                        outputs = [layer3_o.errors(y),layer0.output],\n",
    "                        givens = { x : valid_set_x[index*batch_size : (index+1)*batch_size],\n",
    "                                   y : valid_set_y[index*batch_size : (index+1)*batch_size]\n",
    "                                 }\n",
    "                        )\n",
    "\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "er,imcluster0 = visual(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pylab.gray()\n",
    "\n",
    "pylab.imshow(imcluster0[3,0,:,:])\n",
    "#pylab.savefig('im01.png')\n",
    "\n",
    "for i in xrange(20):\n",
    "    pylab.imshow(imcluster0[3,i,:,:])\n",
    "    #pylab.show()\n",
    "    pylab.savefig('im%d.png'%(i))\n",
    "#pylab.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
