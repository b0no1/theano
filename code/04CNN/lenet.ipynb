{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 960\n"
     ]
    }
   ],
   "source": [
    "## >> http://deeplearning.net/tutorial/lenet.html << ##\n",
    "import numpy as np\n",
    "\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import theano.tensor.nnet as conv\n",
    "\n",
    "from theano.tensor.signal import downsample\n",
    "\n",
    "from logistic import load_data,LogisticRegression\n",
    "from mlp import HiddenLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConvPoolLayer(object):\n",
    "    def __init__(self,rng,input,filter_shape,image_shape, pool_size=(2,2) ):\n",
    "        # check if filter shape matches the input shape\n",
    "        assert image_shape[1] == filter_shape[1]\n",
    "        # >>>> self.input = input\n",
    "        # number of inputs to each hidden unit: fan_in\n",
    "        fan_in = np.prod(filter_shape[1:]) # 1x5x5 : receptive field 5x5 of grayscale image\n",
    "        # fan_out to lower layer (left)\n",
    "        #  for gradient propagation\n",
    "        #   20 * 5x5 connections\n",
    "        fan_out = filter_shape[0] * np.prod(filter_shape[2:]) # 20 * (5x5) : nkern[0] * (5x5)\n",
    "        # random initialization of weights\n",
    "        wbound = np.sqrt(6. / (fan_in + fan_out))\n",
    "        wval = np.asarray(rng.uniform(low = -wbound, high = wbound, size=filter_shape),\n",
    "                          dtype = theano.config.floatX)\n",
    "        self.w = theano.shared(wval,name='w',borrow = True)\n",
    "        # bias term \n",
    "        self.b = theano.shared(np.zeros((filter_shape[0],),dtype=theano.config.floatX),name='b', borrow=True)\n",
    "        # convol operation\n",
    "        conv_out = conv.conv2d(input,self.w,filter_shape=filter_shape,image_shape=image_shape)\n",
    "        # pooling : downsampling\n",
    "        pooled = downsample.max_pool_2d(input=conv_out,ds=pool_size,ignore_border=True)\n",
    "        # apply non-linearity and bias to pooled output\n",
    "        #  dimshuffle : convert shape of bias from (filter_shape[0],) to (1, n_filters, 1, 1)\n",
    "        self.output = T.tanh(pooled + self.b.dimshuffle('x',0,'x','x'))\n",
    "        # store params\n",
    "        self.params = [self.w,self.b]\n",
    "        self.input = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data\n",
    "datasets = load_data('mnist.pkl.gz')\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "train_set_x, train_set_y = datasets[0]\n",
    "valid_set_x, valid_set_y = datasets[1]\n",
    "test_set_x, test_set_y = datasets[2]\n",
    "\n",
    "# compute number of minibatches for training, validation and testing\n",
    "n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "n_valid_batches = valid_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "n_test_batches = test_set_x.get_value(borrow=True).shape[0] / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = T.matrix('x')\n",
    "y = T.ivector('y')\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "# convert input x to form (batch_size,1,28,28)\n",
    "layer0_input = x.reshape((batch_size,1,28,28))\n",
    "\n",
    "# setup random stream\n",
    "rng = np.random.RandomState(123455)\n",
    "\n",
    "# build layer0\n",
    "layer0 = ConvPoolLayer(rng=rng,input=layer0_input,\n",
    "                      image_shape=(batch_size,1,28,28),\n",
    "                      filter_shape=(20,1,5,5))\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Layer 1 setup ##\n",
    "layer1 = ConvPoolLayer(rng=rng,input=layer0.output,\n",
    "                      image_shape=(batch_size,20,12,12),\n",
    "                      filter_shape=(50,20,5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Layer 2 : Hidden Layer setup ##\n",
    "# layer1 output shape : batch_sizex50x4x4\n",
    "# layer2_h input shape req : batch_size x (50*4*4)\n",
    "layer2_h_input = layer1.output.flatten(2)\n",
    "# n_in = 50x4x4 pixels; n_out = 500 hidden nodes\n",
    "layer2_h = HiddenLayer(rng=rng,input=layer2_h_input,n_in=50*4*4,n_out=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Layer 3 : Output layer : LogisticRegression\n",
    "layer3_o = LogisticRegression(input=layer2_h.output,n_in=500,n_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost \n",
    "cost = layer3_o.neg_log_likelihood(y)\n",
    "# >> setup gradient expression <<\n",
    "### Need :parameters\n",
    "params = layer3_o.params + layer2_h.params + layer1.params + layer0.params\n",
    "gparams = T.grad(cost,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Updates ##\n",
    "updates = [(param, param - gparam*learning_rate) \n",
    "              for param,gparam in zip(params,gparams)]\n",
    "\n",
    "\n",
    "index = T.lscalar('index')\n",
    "# compile train\n",
    "train = theano.function(inputs=[index],\n",
    "                        outputs=cost,\n",
    "                        updates=updates,\n",
    "                        givens = { x : train_set_x[index*batch_size : (index +1)*batch_size],\n",
    "                                   y : train_set_y[index*batch_size : (index +1)*batch_size]}\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  0  : cost :  0.113680385053\n",
      "iteration  1  : cost :  0.112653717399\n",
      "iteration  2  : cost :  0.111653864384\n",
      "iteration  3  : cost :  0.110670574009\n",
      "iteration  4  : cost :  0.109706357121\n",
      "iteration  5  : cost :  0.108763627708\n",
      "iteration  6  : cost :  0.107837550342\n",
      "iteration  7  : cost :  0.10692743212\n",
      "iteration  8  : cost :  0.106033541262\n",
      "iteration  9  : cost :  0.105159319937\n",
      "iteration  10  : cost :  0.104302830994\n",
      "iteration  11  : cost :  0.103467419744\n",
      "iteration  12  : cost :  0.10264454782\n",
      "iteration  13  : cost :  0.101835392416\n",
      "iteration  14  : cost :  0.101043917239\n",
      "iteration  15  : cost :  0.100261412561\n",
      "iteration  16  : cost :  0.0994883701205\n",
      "iteration  17  : cost :  0.0987267270684\n",
      "iteration  18  : cost :  0.0979755520821\n",
      "iteration  19  : cost :  0.097239561379\n",
      "iteration  20  : cost :  0.0965143442154\n",
      "iteration  21  : cost :  0.0957981869578\n",
      "iteration  22  : cost :  0.0950925275683\n",
      "iteration  23  : cost :  0.0943966805935\n",
      "iteration  24  : cost :  0.0937125980854\n",
      "iteration  25  : cost :  0.0930378511548\n",
      "iteration  26  : cost :  0.0923770591617\n",
      "iteration  27  : cost :  0.0917250439525\n",
      "iteration  28  : cost :  0.0910801589489\n",
      "iteration  29  : cost :  0.0904499515891\n",
      "iteration  30  : cost :  0.0898273587227\n",
      "iteration  31  : cost :  0.0892138257623\n",
      "iteration  32  : cost :  0.0886091664433\n",
      "iteration  33  : cost :  0.0880112424493\n",
      "iteration  34  : cost :  0.0874211937189\n",
      "iteration  35  : cost :  0.0868406817317\n",
      "iteration  36  : cost :  0.0862646251917\n",
      "iteration  37  : cost :  0.085695721209\n",
      "iteration  38  : cost :  0.0851368755102\n",
      "iteration  39  : cost :  0.0845851302147\n",
      "iteration  40  : cost :  0.0840403810143\n",
      "iteration  41  : cost :  0.0835013240576\n",
      "iteration  42  : cost :  0.0829667001963\n",
      "iteration  43  : cost :  0.0824391022325\n",
      "iteration  44  : cost :  0.0819183066487\n",
      "iteration  45  : cost :  0.0814032629132\n",
      "iteration  46  : cost :  0.0808916389942\n",
      "iteration  47  : cost :  0.0803851038218\n",
      "iteration  48  : cost :  0.0798851326108\n",
      "iteration  49  : cost :  0.0793961584568\n",
      "iteration  50  : cost :  0.0789155885577\n",
      "iteration  51  : cost :  0.0784413516521\n",
      "iteration  52  : cost :  0.0779721662402\n",
      "iteration  53  : cost :  0.0775105953217\n",
      "iteration  54  : cost :  0.0770537853241\n",
      "iteration  55  : cost :  0.0766015276313\n",
      "iteration  56  : cost :  0.0761543661356\n",
      "iteration  57  : cost :  0.0757114887238\n",
      "iteration  58  : cost :  0.0752736330032\n",
      "iteration  59  : cost :  0.0748393088579\n",
      "iteration  60  : cost :  0.0744105353951\n",
      "iteration  61  : cost :  0.0739845111966\n",
      "iteration  62  : cost :  0.0735648870468\n",
      "iteration  63  : cost :  0.0731528475881\n",
      "iteration  64  : cost :  0.0727481544018\n",
      "iteration  65  : cost :  0.0723472312093\n",
      "iteration  66  : cost :  0.071951046586\n",
      "iteration  67  : cost :  0.0715586990118\n",
      "iteration  68  : cost :  0.0711704865098\n",
      "iteration  69  : cost :  0.0707881003618\n",
      "iteration  70  : cost :  0.07040951401\n",
      "iteration  71  : cost :  0.0700350627303\n",
      "iteration  72  : cost :  0.0696672201157\n",
      "iteration  73  : cost :  0.0692996233702\n",
      "iteration  74  : cost :  0.0689342990518\n",
      "iteration  75  : cost :  0.0685736984015\n",
      "iteration  76  : cost :  0.0682154670358\n",
      "iteration  77  : cost :  0.0678587779403\n",
      "iteration  78  : cost :  0.0675072446465\n",
      "iteration  79  : cost :  0.0671594366431\n",
      "iteration  80  : cost :  0.0668154582381\n",
      "iteration  81  : cost :  0.066472761333\n",
      "iteration  82  : cost :  0.0661311820149\n",
      "iteration  83  : cost :  0.0657936409116\n",
      "iteration  84  : cost :  0.0654627159238\n",
      "iteration  85  : cost :  0.0651339292526\n",
      "iteration  86  : cost :  0.0648104473948\n",
      "iteration  87  : cost :  0.064488850534\n",
      "iteration  88  : cost :  0.0641673728824\n",
      "iteration  89  : cost :  0.0638499855995\n",
      "iteration  90  : cost :  0.0635343119502\n",
      "iteration  91  : cost :  0.063220076263\n",
      "iteration  92  : cost :  0.0629067271948\n",
      "iteration  93  : cost :  0.0625973045826\n",
      "iteration  94  : cost :  0.0622895658016\n",
      "iteration  95  : cost :  0.0619849264622\n",
      "iteration  96  : cost :  0.0616852454841\n",
      "iteration  97  : cost :  0.0613892525434\n",
      "iteration  98  : cost :  0.0610948801041\n",
      "iteration  99  : cost :  0.0608036406338\n"
     ]
    }
   ],
   "source": [
    "# Actual training #\n",
    "# Actual training begins here\n",
    "minibatch_avg_cost = 0\n",
    "for j in xrange(100):\n",
    "    for i in xrange(n_train_batches):\n",
    "        minibatch_avg_cost = train(i)        \n",
    "    print 'iteration ',j,' : cost : ', minibatch_avg_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_error :  0.0134\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "test = theano.function(inputs = [index],\n",
    "                      outputs = layer3_o.errors(y),\n",
    "                      givens = { x : test_set_x[index*batch_size : (index +1)*batch_size],\n",
    "                                 y : test_set_y[index*batch_size : (index +1)*batch_size]\n",
    "                               }\n",
    "                      )\n",
    "error_sum = 0.0\n",
    "for i in xrange(n_test_batches):\n",
    "    error_sum += test(i)\n",
    "print 'avg_error : ',error_sum/n_test_batches\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
