{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## >> Tut : http://deeplearning.net/tutorial/logreg.html <<<\n",
    "\n",
    "import cPickle\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load Data ##\n",
    "def load_data(dataset):\n",
    "    data_dir, data_file = os.path.split(dataset)\n",
    "    if data_dir == \"\" and not os.path.isfile(dataset):\n",
    "        new_path = os.path.join(\n",
    "            os.path.split(__file__)[0],\n",
    "            \"..\",\n",
    "            \"data\",\n",
    "            dataset\n",
    "        )\n",
    "        if os.path.isfile(new_path) or data_file == 'mnist.pkl.gz':\n",
    "            dataset = new_path\n",
    "\n",
    "    if (not os.path.isfile(dataset)) and data_file == 'mnist.pkl.gz':\n",
    "        import urllib\n",
    "        origin = (\n",
    "            'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz'\n",
    "        )\n",
    "        print 'Downloading data from %s' % origin\n",
    "        urllib.urlretrieve(origin, dataset)\n",
    "\n",
    "    print '... loading data'\n",
    "\n",
    "    f = gzip.open(dataset, 'rb')\n",
    "    train_set, valid_set, test_set = cPickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    def shared_dataset(data_xy, borrow=True):\n",
    "        data_x, data_y = data_xy\n",
    "        shared_x = theano.shared(numpy.asarray(data_x,\n",
    "                                               dtype=theano.config.floatX),\n",
    "                                 borrow=borrow)\n",
    "        shared_y = theano.shared(numpy.asarray(data_y,\n",
    "                                               dtype=theano.config.floatX),\n",
    "                                 borrow=borrow)\n",
    "        return shared_x, T.cast(shared_y, 'int32')\n",
    "\n",
    "    test_set_x, test_set_y = shared_dataset(test_set)\n",
    "    valid_set_x, valid_set_y = shared_dataset(valid_set)\n",
    "    train_set_x, train_set_y = shared_dataset(train_set)\n",
    "\n",
    "    rval = [(train_set_x, train_set_y), (valid_set_x, valid_set_y),\n",
    "            (test_set_x, test_set_y)]\n",
    "    return rval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression Class\n",
    "\n",
    "class LogisticReg(object):\n",
    "    def __init__(self, input, n_in, n_out):\n",
    "        self.w = theano.shared(\n",
    "            value=numpy.zeros(\n",
    "                (n_in, n_out),\n",
    "                dtype=theano.config.floatX\n",
    "            ),\n",
    "            name='w',\n",
    "            borrow=True\n",
    "        )\n",
    "         # initialize the biases b as a vector of n_out 0s\n",
    "        self.b = theano.shared(\n",
    "            value=numpy.zeros(\n",
    "                (n_out,),\n",
    "                dtype=theano.config.floatX\n",
    "            ),\n",
    "            name='b',\n",
    "            borrow=True\n",
    "        )\n",
    "        self.p_y_given_x = T.nnet.softmax(T.dot(input,self.w) + self.b)\n",
    "        self.y_pred = np.argmax(self.p_y_given_x,axis = 1)\n",
    "        self.params = [self.w, self.b]\n",
    "        self.input = input\n",
    "\n",
    "        \n",
    "    def neg_log_likelihood(self,y):\n",
    "        return -T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[0]), y])\n",
    "    \n",
    "    def errors(self,y):\n",
    "        if y.ndim != self.y_pred.ndim:\n",
    "            raise TypeError(\n",
    "                'y should have the same shape as self.y_pred',\n",
    "                ('y', y.type, 'y_pred', self.y_pred.type)\n",
    "            )\n",
    "        if y.dtype.startswith('int'):\n",
    "            return T.mean(T.neq(self.y_pred, y))\n",
    "        else:\n",
    "            raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Instantiate the class\n",
    "\n",
    "x = T.matrix('x')\n",
    "y = T.ivector('y')\n",
    "\n",
    "index = T.lscalar('index')\n",
    "\n",
    "classifier = LogisticReg(input=x, n_in=28 * 28, n_out=10)\n",
    "\n",
    "cost = classifier.neg_log_likelihood(y)\n",
    "\n",
    "#classifier = Logistic(input=x,n_in=28*28,n_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Train symbolic function : Compile ####\n",
    "\n",
    "# gradients\n",
    "gw,gb = T.grad(cost,[classifier.w,classifier.b])\n",
    "\n",
    "# Update weight and bias\n",
    "updates=[(classifier.w, classifier.w - (0.13*gw) ),(classifier.b, classifier.b - (0.13*gb))]\n",
    "\n",
    "# train function\n",
    "train = theano.function(inputs=[index],\n",
    "                        outputs=[cost],\n",
    "                        updates = updates,\n",
    "                        givens={x : train_set_x[index*batch_size : (index+1)*batch_size],\n",
    "                                y : train_set_y[index*batch_size :(index+1)*batch_size]}                        \n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n"
     ]
    }
   ],
   "source": [
    "## Load dataset ##\n",
    "datasets = load_data('mnist.pkl.gz')\n",
    "\n",
    "train_set_x, train_set_y = datasets[0]\n",
    "valid_set_x, valid_set_y = datasets[1]\n",
    "test_set_x, test_set_y = datasets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print train_set_x.get_value().shape\n",
    "print test_set_x.get_value().shape\n",
    "\n",
    "# Set minibatch size\n",
    "batch_size = 600\n",
    "\n",
    "# compute number of minibatches for training, validation and testing\n",
    "n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "n_valid_batches = valid_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "n_test_batches = test_set_x.get_value(borrow=True).shape[0] / batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  0  : cost :  [array(0.3216033906150585)]\n",
      "iteration  1  : cost :  [array(0.32141156836623513)]\n",
      "iteration  2  : cost :  [array(0.3212224491328717)]\n",
      "iteration  3  : cost :  [array(0.32103596997239303)]\n",
      "iteration  4  : cost :  [array(0.3208520700829759)]\n",
      "iteration  5  : cost :  [array(0.32067069070752896)]\n",
      "iteration  6  : cost :  [array(0.3204917750428766)]\n",
      "iteration  7  : cost :  [array(0.32031526815381706)]\n",
      "iteration  8  : cost :  [array(0.32014111689175667)]\n",
      "iteration  9  : cost :  [array(0.319969269817638)]\n",
      "iteration  10  : cost :  [array(0.3197996771289019)]\n",
      "iteration  11  : cost :  [array(0.3196322905902374)]\n",
      "iteration  12  : cost :  [array(0.319467063467896)]\n",
      "iteration  13  : cost :  [array(0.3193039504673561)]\n",
      "iteration  14  : cost :  [array(0.31914290767414183)]\n",
      "iteration  15  : cost :  [array(0.318983892497611)]\n",
      "iteration  16  : cost :  [array(0.3188268636175405)]\n",
      "iteration  17  : cost :  [array(0.31867178093334736)]\n",
      "iteration  18  : cost :  [array(0.31851860551579686)]\n",
      "iteration  19  : cost :  [array(0.3183672995610534)]\n",
      "iteration  20  : cost :  [array(0.318217826346947)]\n",
      "iteration  21  : cost :  [array(0.31807015019132706)]\n",
      "iteration  22  : cost :  [array(0.31792423641239104)]\n",
      "iteration  23  : cost :  [array(0.3177800512908779)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-7db9edf128f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_train_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mminibatch_avg_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'iteration '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' : cost : '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mminibatch_avg_cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "minibatch_avg_cost = 0\n",
    "for j in xrange(100):\n",
    "    for i in xrange(n_train_batches):\n",
    "        minibatch_avg_cost = train(i)\n",
    "    print 'iteration ',j,' : cost : ',minibatch_avg_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = theano.function(inputs=[index],outputs=classifier.errors(y),\n",
    "                      givens={x : test_set_x[index*batch_size : (index +1)*batch_size],\n",
    "                              y : test_set_y[index*batch_size : (index +1)*batch_size]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch  0  : avg_error :  0.085\n",
      "batch  1  : avg_error :  0.101666666667\n",
      "batch  2  : avg_error :  0.115\n",
      "batch  3  : avg_error :  0.106666666667\n",
      "batch  4  : avg_error :  0.0916666666667\n",
      "batch  5  : avg_error :  0.0716666666667\n",
      "batch  6  : avg_error :  0.111666666667\n",
      "batch  7  : avg_error :  0.0983333333333\n",
      "batch  8  : avg_error :  0.0633333333333\n",
      "batch  9  : avg_error :  0.0616666666667\n",
      "batch  10  : avg_error :  0.0666666666667\n",
      "batch  11  : avg_error :  0.0433333333333\n",
      "batch  12  : avg_error :  0.02\n",
      "batch  13  : avg_error :  0.0716666666667\n",
      "batch  14  : avg_error :  0.0133333333333\n",
      "batch  15  : avg_error :  0.0483333333333\n"
     ]
    }
   ],
   "source": [
    "for j in xrange(n_test_batches):\n",
    "    avg_test_error = test(j)\n",
    "    print 'batch ',j,' : avg_error : ',avg_test_error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = theano.function(inputs=[index],outputs=classifier.errors(y),\n",
    "                      givens={x : valid_set_x[index*batch_size : (index +1)*batch_size],\n",
    "                              y : valid_set_y[index*batch_size : (index +1)*batch_size]})\n",
    "\n",
    "for j in xrange(n_valid_batches):\n",
    "    avg_v_error = test(j)\n",
    "    print 'batch ',j,' : avg_error : ',avg_valid_error\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
